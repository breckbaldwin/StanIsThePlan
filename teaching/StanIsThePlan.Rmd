---
title: "Stan Is The Plan"
author: "Jonathan Auerbach, Breck Baldwin"
date: "8/17/2019"
output: 
  ioslides_presentation: 
    highlight: null
    incremental: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Course Outline

- Programmer focused on mechanics, not statistical theory
- Enough statistics to get you started understanding what is going on overall
- Get past high probability failure points

```{r fig.height=3}
hist(rexp(100,1),xlab="Stan Knowledge in Days",ylab="% Chance of Failure",main="Liklihood of Failure to Learn Stan")
```

## The State of Science

* Averages are old school
  + Easy science has been done, broad strokes of reality sorted
  + Population pooled theory worked out with N's in the 1,000s
* Human understandability of modeling 
  + Deep Learning utterly opaque
  + Do you really want black box AI doing prison sentencing?
* Most of science is small to medium data
  + Clinical trials in the 10's to 100's of subjects
  + Big Data approaches fail

## The Bayesian Modeling Response: The Road Kill Smartphone App

<img src="img/zebra.jpg" width=400> 

"Oh, that was easy," says Man, and for an encore goes on to prove that black is white and gets himself killed on the next zebra crossing.‚Äù Hitchikers Guide to the Galaxy

Sort of Vision Zero project that keeps track of dangerous Zebra crossings via crowd sourced data. "Make is safe to walk and be absorbed in your phone"

## 

## Deep Learning Approach

- Go/No Go decision. 
<img black box>
- 10000 training instances
  + 5100 survive, 4900 die
- Maximum Liklihood Estimate says go as will most any machine learning algo. 
  + 5100/10000 = 51% go. 
- High dimensional decisions you cannot obviously know the meaning of .51 
  + No reliable calibration. Classifiers reporting scores of .2 can actually be .9 precise.

## zebra.stan

```{stan output.var=zebra.stan}
transformed data {
   int number_of_successful_crossings = 5100;
   int number_of_crossing_attempts =10000;
}
parameters {
   real<lower=0,upper=1> safe_to_pass;
}
model {
  number_of_successful_crossings
	  ~ binomial(number_of_crossing_attempts,safe_to_pass);
}
```

```{r setup, include=TRUE, echo=FALSE}
library(rstan)
library("shinystan")

fit <-
  sampling(zebra.stan)

print(fit)

launch_shinystan(fit)
```

## Bayesian Approach
- Let us look at a posterior for the binomial distribution:
```{r}
hist(rbinom(1000,100,.51))
```
1000 times we have 100 people use the zebra crossing and the x axis is the number that survive.

## What does 'successes ~ binomial(attempts,probability)' mean?

- 1 ~ binomial(2,prob) returns a probability. 
  + 1 ~ bernoulli(prob) & 0 ~ bernoulli(prob)
- Has awful property that we assign probabilities to a parameter than is itself a probability. 
- binomial can be run in various directions
  + ?successes? = binomial_rng(N_attempts, theta_config_prob);
  + 
## How does Sampling work?

- We want to know the probability distribution of one or more params of interest
- Analytic Solutions
  + need example
- Grid Approximation
- Metropolis-Hastings
- successes ~ binomial(attempts,probability)
- target += binomial(successes 

## Grid Approximation
  - Test values from the support of a variable being estimated. 
  - One variable is a comb approximation.
  - `successes ~ binomial(attempts,probability)`
```{r}
vals = c(.0,.1,.2,.3,.4,.5,.6,.7,.8,.9,1.0);
total = sum(dbinom(5,10,vals))
sum(dbinom(5,10,vals)/total)

```

## Metropolis Hastings

- Foundation of current Stan sampler
- Look at the single parameter case.
- Look at acceptance rate.
- Exercise: do the two parameter case. 
- Suffers from dimensionality scaling problems.

## Deconstructing a Stan program

- HelloWorld.stan
- Interface with external data
- Interface with external data consumers
  + RStudio
  + ShinyStan
- User defined binomial fn
  + underflow case
  + correct implementation

## Where are we?

- You ought to have a good idea of what sampling is.
- Some familiarity of what a distribution is.
- Now we are going to do some modeling.

## Big Models beget Small Data 
- what do I already assume/know? (prior)
- cars aware y/n
- special signage y/n
- pedestrians expect y/n
- what about similar looking locations? (pooling)

## The Bayesian Narrative

1. Factor in what you know (Prior)
2. Model phenomenion as a combo of data and liklihood
3. Examine posterior

## Prior integration

## Mechanistic integration

## Pooling integration





## Slide with R Output

```{r cars, echo = TRUE}
summary(cars)
```

## Slide with Plot

```{r pressure}
plot(pressure)
```

